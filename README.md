# Scriptorium — Scraper and parser for list-org.com
---
!!! **ВАЖНО**: Все данные для скрипта взяты с сайта https://www.list-org.com/
## Запуск
---
Скопировать репозиторий
```bash
git clone https://github.com/Eleverkuhn/Scriptorium
cd scriptorium
```
Создать виртуальное окружение
```bash
python3 -m venv my-env
source my-env/bin/activate
```
Установить зависимости
```bash
pip install -r requirements.txt
playwright install chromium
```
Выполнить
```
python3 main.py
```
### Примечание
---
Скрипт может не запускаться, если вы в недавнее время часто посещали  [list-org](https://www.list-org.com/). Проблема связана со странной логикой работы капчи. В какие-то дни проверки работы программы мне удавалось без проблем запустить скрипт на 10 и более реквестов, в какие-то не давало и больше двух. В случае ошибок выполните следующие команды:
```bash
cp src/backup/data_0.xlsx src/company_data
cp src/backup/cache.json src/
```
## Отчёт
---
### Подход
---
#### Источники
---
Первым делом я проверил ресурсы, указанные в тех задании и посмотрел, являются ли они платными и предоставляет ли какой-либо из них публичный API. Убедившись, что данные так просто достать не получится я обратился к сайту ЕГРЮЛ. ФНС открывает доступ только по официальным обращением, а сайт [ofdata](https://ofdata.ru/open-data) бесплатно позволяет скачать лишь SQL дамп на 15 гигабайт. Посовещавшись с Chat-GPT я нашёл репозиторий [RFSD](https://github.com/irlcode/RFSD), но там данные не обновлялись с 2023 года и я так как источник не является официальным, я остановился на [list-org](https://www.list-org.com/).
List-org позволяет сразу отфильтровать данные по нужным для задания параметрам (количество сотрудников и ОКВЭД-код). Хоть количество реквестов для бота и ограничено до 10 (дальше требуется ввести капчу), мне удалось найти способ использовать их эффективно и получить информацию о российских IT компаниях со 100 сотрудниками и выше *програмным* способом
#### Отбор компаний
---
Первичный отбор происходил по ОКВЭД коду 62 (и сопутствующим подкодам), включающему в себя основные направления в IT:
- Разработка
- Консультативные услуги
- Сопровождение существующих компьютерных систем
#### Оценка количества сотрудников
---
[list-org](https://www.list-org.com/) предоставляет данные о количестве сотрудников и позволяет сортировать. Через прямой реквест к их API я отобрал все *действующие* компании с кодом ОКВЭД 62 имеющие более 100 сотрудников и отсортировал их по убыванию.
### Результат работы
---
#### Удалось реализовать
1. **Скрапер**. Програмными методами удалось получить отсортированный и отфильтрованный список 100 российских айти компаний:
	- Я узнал, что загрузка данных зависит от наличия пользовательского cookie
	- Смог выяснить, что [list-org](https://www.list-org.com/) устанавливает пользовательский cookie при обращении к эндпоинту с детальной информацией о компании
	- Использовав связку [playwright](https://github.com/microsoft/playwright) + [requests](https://pypi.org/project/requests/) сэмулировал механизм скачивания xlsx файла
	- Оптимизировал работу, написав кэш-систему. Каждый посещённый эндпоинт и ID каждой компании записывается в JSON файл, что позволяет один раз собрать информацию и не тратить время на постоянное обращение через chromium (playwright работает на удивление медленно) и сократить и так скромное количество свободных реквестов
	- Понять принцип работы эндпоинта для скачивания xlsx файлов, что позволило увеличить количество скачиваемых данных и сократить количество запросов (от части это не совсем получилось, читайте ниже)
2. **Парсер**:
	- Отбор требуемых данных а также дополнительных полей `site`, `region` и `contacts`
	- Приведение нескольких разных наименований Москвы (в их оригинальных файлах встречается то `Г. МОСКВА`, то `ГОРОД МОСКВА`)  к единому стандарту
	- Приведение поля `телефон` к единому, более удобочитаемому формату
	- Заполнение пустых полей
#### Не удалось реализовать 
---
1. Рейт-лимит [list-org](https://www.list-org.com/) по разному работал в разные дни, либо я в какой-то момент получил IP блок. Я выстроил всю логику приложения и написал практически всю кодовую базу основываясь на первичных тестах, по результатам которых мне удалось сделать 5 реквестов для сбора данных и 5 реквестов для их скачивания, получив в сумме 250 записей с информацией об ИТ компаниях. В последний день тестов я получал блок через каждое второе обращение и не до конца уверен в работе программы, поэтому если возникают ошибки, следуйте инструкции в пункте [[#Примечание]]
2. Количество данных. Из-за описанной выше причины мне не удалось собрать больше данных. Но скрипт написан таким образом, что в состоянии обработать более 100 записей
3. Планировал собрать все данные, включая доход и описание, но у меня просто не осталось времени. Не получилось написать более осмысленные и продуманные тесты, так как всё это тоже очень сильно затормаживало процесс
### Роль LLM
---
Использовал ChatGPT для:
1. Поиск источников после самостоятельного изучения
2. Поиска инструментов
3. Поиск в документации простых решений. Обычно, когда мне требуется узнать каким образом, к примеру, в pandas можно экспортировать файл проще обратиться к АИ, чем читать документацию
## Использованные библиотеки
---
- pandas
- openpyxl
- playwrigh
- pytest
- requests
